{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"image_top_1\" Completion by learning - Regression\n",
    "\n",
    "Due to the importance of the image_top_1 feature (and the price) in LGBM's ratings, we wish to complete them in a \"smart\" way (not just 0 mode/median or NA). In this notebook we learn image_top_1 from other (non-image) features of our data by training a regression NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glob/intel-python/versions/2018/intelpython3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning:\n",
      "\n",
      "Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%run stephan_modules.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/home/u14303/Avito'\n",
    "HELPER_DATA_PATH = '/home/u14303/Avito/helper_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature enrichment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all engineered features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "Adding basic features...\n",
      "Done adding basic features.\n",
      "Adding image features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u14303/stephan_feature_enrichment.py:65: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "/home/u14303/stephan_feature_enrichment.py:66: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading image features.\n",
      "Loading text features...\n",
      "Done loading text features.\n",
      "Loading aggregated features...\n",
      "Done loading aggregated features.\n",
      "Loading aggregated features...\n",
      "Done loading aggregated features.\n",
      "Cleaning and completing numeric features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u14303/stephan_feature_enrichment.py:172: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "/home/u14303/stephan_feature_enrichment.py:173: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done cleaning numeric features.\n"
     ]
    }
   ],
   "source": [
    "print('loading data...')\n",
    "train, test = load_data(DATA_PATH)\n",
    "train, test = basic_enrichment(train, test, helper_data_path=HELPER_DATA_PATH)\n",
    "train, test = load_image_features(train, test, helper_data_path=HELPER_DATA_PATH)\n",
    "train, test = load_text_features(train, test, helper_data_path=HELPER_DATA_PATH)\n",
    "train, test = add_aggregated_features(train, test, helper_data_path=HELPER_DATA_PATH)\n",
    "train, test = numeric_features_cleaning(train, test, helper_data_path=HELPER_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['item_id',\n",
       " 'user_id',\n",
       " 'region',\n",
       " 'city',\n",
       " 'parent_category_name',\n",
       " 'category_name',\n",
       " 'param_1',\n",
       " 'param_2',\n",
       " 'param_3',\n",
       " 'title',\n",
       " 'description',\n",
       " 'price',\n",
       " 'item_seq_number',\n",
       " 'activation_date',\n",
       " 'user_type',\n",
       " 'image',\n",
       " 'image_top_1',\n",
       " 'deal_probability',\n",
       " 'has_description',\n",
       " 'has_price',\n",
       " 'has_params',\n",
       " 'has_image',\n",
       " 'month',\n",
       " 'day',\n",
       " 'weekday',\n",
       " 'user_ads_count',\n",
       " 'title_description_params',\n",
       " 'img_size',\n",
       " 'img_sharpness',\n",
       " 'img_luminance',\n",
       " 'img_colorfulness',\n",
       " 'img_confidence',\n",
       " 'img_keypoints',\n",
       " 'log_img_sharpness',\n",
       " 'log_img_keypoints',\n",
       " 'title_word_count',\n",
       " 'description_non_regular_chars_ratio',\n",
       " 'description_word_count',\n",
       " 'merged_params_word_count',\n",
       " 'description_sentence_count',\n",
       " 'description_words/sentence_ratio',\n",
       " 'title_capital_letters_ratio',\n",
       " 'description_capital_letters_ratio',\n",
       " 'title_non_regular_chars_ratio',\n",
       " 'title_num_of_newrow_char',\n",
       " 'description_num_of_newrow_char',\n",
       " 'title_num_adj',\n",
       " 'title_num_nouns',\n",
       " 'title_adj_to_len_ratio',\n",
       " 'title_noun_to_len_ratio',\n",
       " 'description_num_adj',\n",
       " 'description_num_nouns',\n",
       " 'description_adj_to_len_ratio',\n",
       " 'description_noun_to_len_ratio',\n",
       " 'title_first_noun_stemmed',\n",
       " 'title_second_noun_stemmed',\n",
       " 'title_third_noun_stemmed',\n",
       " 'description_first_noun_stemmed',\n",
       " 'description_second_noun_stemmed',\n",
       " 'description_third_noun_stemmed',\n",
       " 'title_first_adj_stemmed',\n",
       " 'title_second_adj_stemmed',\n",
       " 'title_third_adj_stemmed',\n",
       " 'description_first_adj_stemmed',\n",
       " 'description_second_adj_stemmed',\n",
       " 'description_third_adj_stemmed',\n",
       " 'title_sentiment',\n",
       " 'description_sentiment',\n",
       " 'avg_days_up_user',\n",
       " 'avg_times_up_user',\n",
       " 'n_user_items',\n",
       " 'log_item_seq_number',\n",
       " 'log_price',\n",
       " 'log_description_word_count']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep real item (ad) IDs for later merge and save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_train_ids = pd.DataFrame(train['item_id'])\n",
    "r_test_ids = pd.DataFrame(test['item_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn the train dataframe to contain all samples we have 'image_top_1' labels for (from original test and train dataframes). Respectively put all samples that we do not have 'image_top_1' labels for in \"test\" dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glob/intel-python/versions/2018/intelpython3/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning:\n",
      "\n",
      "Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train = pd.concat([train, test], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = train[train['image_top_1'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train['image_top_1'].isna() == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### image_top_1\n",
    "\n",
    "It seems to be a continious number.\n",
    "\n",
    "Unlike the previous notebook, here we'll try predicting it by regression (It's still a number with some ordinal importance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_target = train['image_top_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize features towards input to an NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick features to feed into the NN that will be used to learn 'image_top_1'. Pay attention that we exclude image features as for samples with missing image_top_1s, there is no images (and thus no image features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_feature = 'title_description_params'\n",
    "cat_features = ['user_type', \\\n",
    "                'region', 'city', \\\n",
    "                'parent_category_name', 'category_name', 'param_1', 'param_2', 'param_3', \\\n",
    "                'month', 'day', 'weekday', \\\n",
    "                'has_description', 'has_price', 'has_params']\n",
    "cont_ord_features = ['avg_days_up_user', 'avg_times_up_user', 'n_user_items', 'user_ads_count', \\\n",
    "                     'log_price', 'log_item_seq_number', \\\n",
    "                     'title_word_count', 'log_description_word_count', 'merged_params_word_count', \\\n",
    "                     'description_non_regular_chars_ratio', 'title_capital_letters_ratio', 'description_capital_letters_ratio', \\\n",
    "                     'title_non_regular_chars_ratio', 'title_adj_to_len_ratio', 'title_noun_to_len_ratio',\\\n",
    "                     'title_sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text features\n",
    "\n",
    "TF-IDF vectorize merged texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting tf-idf on text...\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "text_tfidf_dim = 7500\n",
    "\n",
    "train_x_text = train[text_feature].astype('str')\n",
    "test_x_text = test[text_feature].astype('str')\n",
    "all_text = np.hstack([train_x_text, test_x_text])\n",
    "\n",
    "tfidf_enc = TfidfVectorizer(max_features=text_tfidf_dim, ngram_range=(1, 1), dtype=np.float32)\n",
    "print('Fitting tf-idf on text...')\n",
    "tfidf_enc.fit(all_text)\n",
    "print('Done.')\n",
    "\n",
    "del all_text\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF: applying encoder on text...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "print('TF-IDF: applying encoder on text...')\n",
    "\n",
    "train_x_text = tfidf_enc.transform(train_x_text)\n",
    "test_x_text = tfidf_enc.transform(test_x_text)\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical features.\n",
    "\n",
    "Vectorize all loaded categorical features.\n",
    "\n",
    "\n",
    "See: http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glob/intel-python/versions/2018/intelpython3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "/glob/intel-python/versions/2018/intelpython3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "/glob/intel-python/versions/2018/intelpython3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "/glob/intel-python/versions/2018/intelpython3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_cat = train[cat_features]\n",
    "test_x_cat = test[cat_features]\n",
    "for col in cat_features:\n",
    "    train_x_cat[col] = train_x_cat[col].astype('category')\n",
    "    test_x_cat[col] = test_x_cat[col].astype('category')\n",
    "\n",
    "# Encode to integers.\n",
    "# For vectorization (encoding) we concat both train and test into one\n",
    "all_cat = pd.concat([train_x_cat, test_x_cat], axis = 0)\n",
    "for col in cat_features:\n",
    "    enc = preprocessing.LabelEncoder().fit(all_cat[col])\n",
    "    train_x_cat[col] = enc.transform(train_x_cat[col])\n",
    "    test_x_cat[col] = enc.transform(test_x_cat[col])\n",
    "\n",
    "# One-hot encode:\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(pd.concat([train_x_cat, test_x_cat], axis = 0))\n",
    "train_x_cat = enc.transform(train_x_cat)\n",
    "test_x_cat = enc.transform(test_x_cat)\n",
    "\n",
    "del all_cat\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical(Continious/Ordinal) features\n",
    "Normalize all loaded numeric features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u14303/.local/lib/python3.6/site-packages/pandas/core/frame.py:3790: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "/glob/intel-python/versions/2018/intelpython3/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "/glob/intel-python/versions/2018/intelpython3/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_x_numerical = train[cont_ord_features]\n",
    "test_x_numerical = test[cont_ord_features]\n",
    "train_x_numerical.fillna(0, inplace = True)\n",
    "test_x_numerical.fillna(0, inplace = True)\n",
    "for col in cont_ord_features:\n",
    "    train_x_numerical[col] = train_x_numerical[col].astype('float64')\n",
    "    test_x_numerical[col] = test_x_numerical[col].astype('float64')\n",
    "\n",
    "# Normalize features:\n",
    "train_x_numerical = normalize(train_x_numerical, axis=0)\n",
    "test_x_numerical = normalize(test_x_numerical, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning - Neural Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_hidden_dim = 256\n",
    "cat_hidden_dim = 128\n",
    "merged_hidden_dim = 256\n",
    "out_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "text_tfidf_input (InputLayer)   (None, 7500)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cat_input (InputLayer)          (None, 3822)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "l_hidden_text (Dense)           (None, 256)          1920256     text_tfidf_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "l_hidden_cat (Dense)            (None, 128)          489344      cat_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "numerical_input (InputLayer)    (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 400)          0           l_hidden_text[0][0]              \n",
      "                                                                 l_hidden_cat[0][0]               \n",
      "                                                                 numerical_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "l_merged_hidden (Dense)         (None, 256)          102656      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 1)            257         l_merged_hidden[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 2,512,513\n",
      "Trainable params: 2,512,513\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Text\n",
    "l_text_input = Input(shape=(text_tfidf_dim,), sparse=True, name=\"text_tfidf_input\")\n",
    "l_hidden_text = Dense(text_hidden_dim, activation='relu', \n",
    "                      kernel_regularizer=regularizers.l2(1e-6), name='l_hidden_text')(l_text_input)\n",
    "\n",
    "# Categoricals\n",
    "l_cat_input = Input(shape=(train_x_cat.shape[1],), sparse=True, name=\"cat_input\")\n",
    "l_hidden_cat = Dense(cat_hidden_dim, activation='relu',\n",
    "                     kernel_regularizer=regularizers.l2(1e-6), name='l_hidden_cat')(l_cat_input)\n",
    "\n",
    "# Numerical\n",
    "l_numerical_input = Input(shape=(train_x_numerical.shape[1],), name=\"numerical_input\")\n",
    "\n",
    "# Aggregate all inputs into one hidden layer.\n",
    "l_aggregative = concatenate([l_hidden_text, l_hidden_cat, l_numerical_input])\n",
    "\n",
    "l_merged_hidden = Dense(merged_hidden_dim, activation='relu',\n",
    "                            kernel_regularizer=regularizers.l2(1e-6), name='l_merged_hidden')(l_aggregative)\n",
    "output = Dense(out_dim, name='output')(l_merged_hidden)\n",
    "\n",
    "adam_opt = Adam(lr=0.001)\n",
    "\n",
    "model = Model(inputs=[l_text_input, l_cat_input, l_numerical_input], outputs=[output])\n",
    "model.compile(optimizer=adam_opt, loss='mse')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current batch size: 512\n",
      "Train on 1670998 samples, validate on 185667 samples\n",
      "Epoch 1/1\n",
      "1670998/1670998 [==============================] - 104s 62us/step - loss: 231957.2311 - val_loss: 162973.9747\n",
      "Current batch size: 1024\n",
      "Train on 1670998 samples, validate on 185667 samples\n",
      "Epoch 1/1\n",
      "1670998/1670998 [==============================] - 74s 44us/step - loss: 161030.7514 - val_loss: 161886.4558\n",
      "Current batch size: 2048\n",
      "Epoch 1/1\n",
      "1856665/1856665 [==============================] - 53s 29us/step - loss: 159817.7858\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x154c8c0c6e10>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce_lr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, mode='min', min_delta=0.01,\n",
    "                                  verbose=1, min_lr=0.00001)\n",
    "nbatch_size = 512\n",
    "\n",
    "# Train for nepochs epochs. Each epoch, enlarge batch size by factor 2 (we do this to prevent overfit).\n",
    "nepochs = 2\n",
    "for i in range(nepochs):\n",
    "    print ('Current batch size: {}'.format(nbatch_size))\n",
    "    model.fit({'text_tfidf_input' : train_x_text, 'cat_input' : train_x_cat, 'numerical_input' : train_x_numerical},\n",
    "              [y_target], \n",
    "              validation_split = 0.10, \n",
    "              epochs=1, \n",
    "              batch_size=nbatch_size,\n",
    "              callbacks=[reduce_lr_cb])\n",
    "    nbatch_size *= 2\n",
    "    gc.collect()\n",
    "\n",
    "# Train on all data.\n",
    "print ('Current batch size: {}'.format(nbatch_size))\n",
    "model.fit({'text_tfidf_input' : train_x_text, 'cat_input' : train_x_cat, 'numerical_input' : train_x_numerical},\n",
    "          [y_target],\n",
    "          epochs=1, \n",
    "          batch_size=nbatch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complete missing image_top_1s and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = model.predict({'text_tfidf_input' : train_x_text, 'cat_input': train_x_cat, 'numerical_input': train_x_numerical},)\n",
    "test_predictions = model.predict({'text_tfidf_input' : test_x_text, 'cat_input': test_x_cat, 'numerical_input': test_x_numerical})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_train_df = pd.DataFrame(train['item_id'])\n",
    "res_train_df['image_top_1_regression'] = train_predictions\n",
    "\n",
    "res_test_df = pd.DataFrame(test['item_id'])\n",
    "res_test_df['image_top_1_regression'] = test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>image_top_1_regression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0658628930d4</td>\n",
       "      <td>1693.277954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>838a82cec0a6</td>\n",
       "      <td>401.731018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>d0e88acda491</td>\n",
       "      <td>2793.416992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>f55eed4e831e</td>\n",
       "      <td>1488.851929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>f893190597f3</td>\n",
       "      <td>1957.534790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         item_id  image_top_1_regression\n",
       "19  0658628930d4             1693.277954\n",
       "21  838a82cec0a6              401.731018\n",
       "32  d0e88acda491             2793.416992\n",
       "38  f55eed4e831e             1488.851929\n",
       "55  f893190597f3             1957.534790"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "843.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return array[idx]\n",
    "\n",
    "unique_vals = np.unique(y_target)\n",
    "find_nearest(unique_vals, train_predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_train_df['image_top_1_rounded_regression'] = y_target\n",
    "res_test_df['image_top_1_rounded_regression'] = res_test_df.apply(lambda r:find_nearest(unique_vals, r['image_top_1_regression']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check: compare between existing and learned image_top_1s (distribution wise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>image_top_1_regression</th>\n",
       "      <th>image_top_1_rounded_regression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0658628930d4</td>\n",
       "      <td>1693.277954</td>\n",
       "      <td>1693.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>838a82cec0a6</td>\n",
       "      <td>401.731018</td>\n",
       "      <td>402.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>d0e88acda491</td>\n",
       "      <td>2793.416992</td>\n",
       "      <td>2793.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>f55eed4e831e</td>\n",
       "      <td>1488.851929</td>\n",
       "      <td>1489.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>f893190597f3</td>\n",
       "      <td>1957.534790</td>\n",
       "      <td>1958.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         item_id  image_top_1_regression  image_top_1_rounded_regression\n",
       "19  0658628930d4             1693.277954                          1693.0\n",
       "21  838a82cec0a6              401.731018                           402.0\n",
       "32  d0e88acda491             2793.416992                          2793.0\n",
       "38  f55eed4e831e             1488.851929                          1489.0\n",
       "55  f893190597f3             1957.534790                          1958.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>image_top_1_regression</th>\n",
       "      <th>image_top_1_rounded_regression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b912c3c6a6ad</td>\n",
       "      <td>843.030518</td>\n",
       "      <td>1008.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2dac0150717d</td>\n",
       "      <td>1499.994263</td>\n",
       "      <td>692.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ba83aefab5dc</td>\n",
       "      <td>2918.979004</td>\n",
       "      <td>3032.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02996f1dd2ea</td>\n",
       "      <td>881.998413</td>\n",
       "      <td>796.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7c90be56d2ab</td>\n",
       "      <td>1709.098755</td>\n",
       "      <td>2264.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_id  image_top_1_regression  image_top_1_rounded_regression\n",
       "0  b912c3c6a6ad              843.030518                          1008.0\n",
       "1  2dac0150717d             1499.994263                           692.0\n",
       "2  ba83aefab5dc             2918.979004                          3032.0\n",
       "3  02996f1dd2ea              881.998413                           796.0\n",
       "4  7c90be56d2ab             1709.098755                          2264.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3063"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_train_df['image_top_1_rounded_regression'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2989"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_test_df['image_top_1_rounded_regression'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking good..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.concat([res_train_df, res_test_df], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_train_ids = r_train_ids.merge(res_df, on='item_id', how='left')\n",
    "r_test_ids = r_test_ids.merge(res_df, on='item_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1503424, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_train_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_train_ids.to_csv(\"/home/u14303/Avito/completed_train_image_top_1_reg.csv.gz\", compression='gzip', index=False)\n",
    "r_test_ids.to_csv(\"/home/u14303/Avito/completed_test_image_top_1_reg.csv.gz\", compression='gzip', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Intel, 2018)",
   "language": "python",
   "name": "intel_distribution_of_python_3_2018"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
