{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"image_top_1\" Completion by learning - Classification\n",
    "\n",
    "Due to the importance of the image_top_1 feature (and the price) in LGBM's ratings, we wish to complete them in a \"smart\" way (not just 0 mode/median or NA). In this notebook we learn image_top_1 from other (non-image) features of our data by training a classification NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glob/intel-python/versions/2018/intelpython3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning:\n",
      "\n",
      "Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%run stephan_modules.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/home/u14303/Avito'\n",
    "HELPER_DATA_PATH = '/home/u14303/Avito/helper_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature enrichment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all engineered features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "Adding basic features...\n",
      "Done adding basic features.\n",
      "Adding image features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u14303/stephan_feature_enrichment.py:65: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "/home/u14303/stephan_feature_enrichment.py:66: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading image features.\n",
      "Loading text features...\n",
      "Done loading text features.\n",
      "Loading aggregated features...\n",
      "Done loading aggregated features.\n",
      "Loading aggregated features...\n",
      "Done loading aggregated features.\n",
      "Cleaning and completing numeric features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u14303/stephan_feature_enrichment.py:172: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "/home/u14303/stephan_feature_enrichment.py:173: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done cleaning numeric features.\n"
     ]
    }
   ],
   "source": [
    "print('loading data...')\n",
    "train, test = load_data(DATA_PATH)\n",
    "train, test = basic_enrichment(train, test, helper_data_path=HELPER_DATA_PATH)\n",
    "train, test = load_image_features(train, test, helper_data_path=HELPER_DATA_PATH)\n",
    "train, test = load_text_features(train, test, helper_data_path=HELPER_DATA_PATH)\n",
    "train, test = add_aggregated_features(train, test, helper_data_path=HELPER_DATA_PATH)\n",
    "train, test = numeric_features_cleaning(train, test, helper_data_path=HELPER_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['item_id',\n",
       " 'user_id',\n",
       " 'region',\n",
       " 'city',\n",
       " 'parent_category_name',\n",
       " 'category_name',\n",
       " 'param_1',\n",
       " 'param_2',\n",
       " 'param_3',\n",
       " 'title',\n",
       " 'description',\n",
       " 'price',\n",
       " 'item_seq_number',\n",
       " 'activation_date',\n",
       " 'user_type',\n",
       " 'image',\n",
       " 'image_top_1',\n",
       " 'deal_probability',\n",
       " 'has_description',\n",
       " 'has_price',\n",
       " 'has_params',\n",
       " 'has_image',\n",
       " 'month',\n",
       " 'day',\n",
       " 'weekday',\n",
       " 'user_ads_count',\n",
       " 'title_description_params',\n",
       " 'img_size',\n",
       " 'img_sharpness',\n",
       " 'img_luminance',\n",
       " 'img_colorfulness',\n",
       " 'img_confidence',\n",
       " 'img_keypoints',\n",
       " 'log_img_sharpness',\n",
       " 'log_img_keypoints',\n",
       " 'title_word_count',\n",
       " 'description_non_regular_chars_ratio',\n",
       " 'description_word_count',\n",
       " 'merged_params_word_count',\n",
       " 'description_sentence_count',\n",
       " 'description_words/sentence_ratio',\n",
       " 'title_capital_letters_ratio',\n",
       " 'description_capital_letters_ratio',\n",
       " 'title_non_regular_chars_ratio',\n",
       " 'title_num_of_newrow_char',\n",
       " 'description_num_of_newrow_char',\n",
       " 'title_num_adj',\n",
       " 'title_num_nouns',\n",
       " 'title_adj_to_len_ratio',\n",
       " 'title_noun_to_len_ratio',\n",
       " 'description_num_adj',\n",
       " 'description_num_nouns',\n",
       " 'description_adj_to_len_ratio',\n",
       " 'description_noun_to_len_ratio',\n",
       " 'title_first_noun_stemmed',\n",
       " 'title_second_noun_stemmed',\n",
       " 'title_third_noun_stemmed',\n",
       " 'description_first_noun_stemmed',\n",
       " 'description_second_noun_stemmed',\n",
       " 'description_third_noun_stemmed',\n",
       " 'title_first_adj_stemmed',\n",
       " 'title_second_adj_stemmed',\n",
       " 'title_third_adj_stemmed',\n",
       " 'description_first_adj_stemmed',\n",
       " 'description_second_adj_stemmed',\n",
       " 'description_third_adj_stemmed',\n",
       " 'title_sentiment',\n",
       " 'description_sentiment',\n",
       " 'avg_days_up_user',\n",
       " 'avg_times_up_user',\n",
       " 'n_user_items',\n",
       " 'log_item_seq_number',\n",
       " 'log_price',\n",
       " 'log_description_word_count']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep real item (ad) IDs for later merge and save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_train_ids = pd.DataFrame(train['item_id'])\n",
    "r_test_ids = pd.DataFrame(test['item_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn the train dataframe to contain all samples we have 'image_top_1' labels for (from original test and train dataframes). Respectively put all samples that we do not have 'image_top_1' labels for in \"test\" dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glob/intel-python/versions/2018/intelpython3/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning:\n",
      "\n",
      "Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train = pd.concat([train, test], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = train[train['image_top_1'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train['image_top_1'].isna() == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### image_top_1\n",
    "image_top_1 seems to be a continious number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3063"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_number = train['image_top_1'].nunique()\n",
    "cat_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But really its some kind of an ordinal class. We try to learn it as if it was a class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1541ffa7edd8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1kAAAJCCAYAAAAyZw3fAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15425f2f9e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train['image_top_1'].plot.hist(alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "# encode image_top_one into integer class values\n",
    "labelenc = LabelEncoder()\n",
    "y_target = train['image_top_1']\n",
    "labelenc.fit(y_target)\n",
    "image_top_1_labels = labelenc.transform(train['image_top_1'])\n",
    "image_top_1_onehot = np_utils.to_categorical(image_top_1_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize features towards input to an NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick features to feed into the NN that will be used to learn 'image_top_1' in a \"classification\" method. Pay attention that we exclude image features as for samples with missing image_top_1s, there is no images (and thus no image features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_feature = 'title_description_params'\n",
    "cat_features = ['user_type', \\\n",
    "                'region', 'city', \\\n",
    "                'parent_category_name', 'category_name', 'param_1', 'param_2', 'param_3', \\\n",
    "                'month', 'day', 'weekday', \\\n",
    "                'has_description', 'has_price', 'has_params']\n",
    "cont_ord_features = ['avg_days_up_user', 'avg_times_up_user', 'n_user_items', 'user_ads_count', \\\n",
    "                     'log_price', 'log_item_seq_number', \\\n",
    "                     'title_word_count', 'description_word_count', 'merged_params_word_count', \\\n",
    "                     'description_non_regular_chars_ratio', 'title_capital_letters_ratio','description_capital_letters_ratio', \\\n",
    "                     'title_non_regular_chars_ratio', 'title_adj_to_len_ratio', 'title_noun_to_len_ratio',\\\n",
    "                     'title_sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text features\n",
    "\n",
    "TF-IDF vectorize merged texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting tf-idf on text...\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "text_tfidf_dim = 7500\n",
    "\n",
    "train_x_text = train[text_feature].astype('str')\n",
    "test_x_text = test[text_feature].astype('str')\n",
    "all_text = np.hstack([train_x_text, test_x_text])\n",
    "\n",
    "tfidf_enc = TfidfVectorizer(max_features=text_tfidf_dim, ngram_range=(1, 1), dtype=np.float32)\n",
    "print('Fitting tf-idf on text...')\n",
    "tfidf_enc.fit(all_text)\n",
    "print('Done.')\n",
    "\n",
    "del all_text\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF: applying encoder on text...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "print('TF-IDF: applying encoder on text...')\n",
    "\n",
    "train_x_text = tfidf_enc.transform(train_x_text)\n",
    "test_x_text = tfidf_enc.transform(test_x_text)\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical features.\n",
    "\n",
    "Vectorize all loaded categorical features.\n",
    "\n",
    "\n",
    "See: http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glob/intel-python/versions/2018/intelpython3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "/glob/intel-python/versions/2018/intelpython3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "/glob/intel-python/versions/2018/intelpython3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "/glob/intel-python/versions/2018/intelpython3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_cat = train[cat_features]\n",
    "test_x_cat = test[cat_features]\n",
    "for col in cat_features:\n",
    "    train_x_cat[col] = train_x_cat[col].astype('category')\n",
    "    test_x_cat[col] = test_x_cat[col].astype('category')\n",
    "\n",
    "# Encode to integers.\n",
    "# For vectorization (encoding) we concat both train and test into one\n",
    "all_cat = pd.concat([train_x_cat, test_x_cat], axis = 0)\n",
    "for col in cat_features:\n",
    "    enc = preprocessing.LabelEncoder().fit(all_cat[col])\n",
    "    train_x_cat[col] = enc.transform(train_x_cat[col])\n",
    "    test_x_cat[col] = enc.transform(test_x_cat[col])\n",
    "\n",
    "# One-hot encode:\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(pd.concat([train_x_cat, test_x_cat], axis = 0))\n",
    "train_x_cat = enc.transform(train_x_cat)\n",
    "test_x_cat = enc.transform(test_x_cat)\n",
    "\n",
    "del all_cat\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical(Continious/Ordinal) features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize all loaded numeric features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u14303/.local/lib/python3.6/site-packages/pandas/core/frame.py:3790: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "/glob/intel-python/versions/2018/intelpython3/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "/glob/intel-python/versions/2018/intelpython3/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_x_numerical = train[cont_ord_features]\n",
    "test_x_numerical = test[cont_ord_features]\n",
    "train_x_numerical.fillna(0, inplace = True)\n",
    "test_x_numerical.fillna(0, inplace = True)\n",
    "for col in cont_ord_features:\n",
    "    train_x_numerical[col] = train_x_numerical[col].astype('float64')\n",
    "    test_x_numerical[col] = test_x_numerical[col].astype('float64')\n",
    "\n",
    "# Normalize features:\n",
    "train_x_numerical = normalize(train_x_numerical, axis=0)\n",
    "test_x_numerical = normalize(test_x_numerical, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning - Neural Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_hidden_dim = 256\n",
    "cat_hidden_dim = 128\n",
    "merged_hidden_dim = 256\n",
    "out_dim = cat_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "text_tfidf_input (InputLayer)   (None, 7500)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cat_input (InputLayer)          (None, 3822)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "l_hidden_text (Dense)           (None, 256)          1920256     text_tfidf_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "l_hidden_cat (Dense)            (None, 128)          489344      cat_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "numerical_input (InputLayer)    (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 400)          0           l_hidden_text[0][0]              \n",
      "                                                                 l_hidden_cat[0][0]               \n",
      "                                                                 numerical_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "l_merged_hidden (Dense)         (None, 256)          102656      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 3063)         787191      l_merged_hidden[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 3,299,447\n",
      "Trainable params: 3,299,447\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Text\n",
    "l_text_input = Input(shape=(text_tfidf_dim,), sparse=True, name=\"text_tfidf_input\")\n",
    "l_hidden_text = Dense(text_hidden_dim, activation='relu', \n",
    "                      kernel_regularizer=regularizers.l2(1e-6), name='l_hidden_text')(l_text_input)\n",
    "\n",
    "# Categoricals\n",
    "l_cat_input = Input(shape=(train_x_cat.shape[1],), sparse=True, name=\"cat_input\")\n",
    "l_hidden_cat = Dense(cat_hidden_dim, activation='relu',\n",
    "                     kernel_regularizer=regularizers.l2(1e-6), name='l_hidden_cat')(l_cat_input)\n",
    "\n",
    "# Numerical\n",
    "l_numerical_input = Input(shape=(train_x_numerical.shape[1],), name=\"numerical_input\")\n",
    "\n",
    "# Aggregate all inputs into one hidden layer.\n",
    "l_aggregative = concatenate([l_hidden_text, l_hidden_cat, l_numerical_input])\n",
    "\n",
    "l_merged_hidden = Dense(merged_hidden_dim, activation='relu',\n",
    "                            kernel_regularizer=regularizers.l2(1e-6), name='l_merged_hidden')(l_aggregative)\n",
    "output = Dense(out_dim, activation='softmax', name='output')(l_merged_hidden)\n",
    "\n",
    "adam_opt = Adam(lr=0.001)\n",
    "model = Model(inputs=[l_text_input, l_cat_input, l_numerical_input], outputs=[output])\n",
    "model.compile(optimizer=adam_opt,\n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current batch size: 512\n",
      "Train on 1670998 samples, validate on 185667 samples\n",
      "Epoch 1/1\n",
      "1670998/1670998 [==============================] - 274s 164us/step - loss: 3.2320 - acc: 0.3679 - val_loss: 2.8256 - val_acc: 0.4181\n",
      "Current batch size: 1024\n",
      "Train on 1670998 samples, validate on 185667 samples\n",
      "Epoch 1/1\n",
      "1670998/1670998 [==============================] - 229s 137us/step - loss: 2.6948 - acc: 0.4322 - val_loss: 2.7455 - val_acc: 0.4303\n",
      "Current batch size: 2048\n",
      "Epoch 1/1\n",
      "1856665/1856665 [==============================] - 227s 122us/step - loss: 2.6009 - acc: 0.4444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1540e956a278>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce_lr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, mode='min', min_delta=0.01,\n",
    "                                  verbose=1, min_lr=0.0001)\n",
    "nbatch_size = 512\n",
    "\n",
    "# Train for iters*1 epochs. After each iteration enlarge batch size by factor 2 (we do this to prevent overfit).\n",
    "iters = 2\n",
    "for i in range(iters):\n",
    "    print ('Current batch size: {}'.format(nbatch_size))\n",
    "    model.fit({'text_tfidf_input': train_x_text, 'cat_input': train_x_cat, 'numerical_input': train_x_numerical},\n",
    "              [image_top_1_onehot], \n",
    "              validation_split = 0.10, \n",
    "              epochs=1, \n",
    "              batch_size=nbatch_size, \n",
    "              callbacks=[reduce_lr_cb])\n",
    "    nbatch_size *= 2\n",
    "\n",
    "# Train on all data.\n",
    "print ('Current batch size: {}'.format(nbatch_size))\n",
    "model.fit({'text_tfidf_input': train_x_text, 'cat_input': train_x_cat, 'numerical_input': train_x_numerical},\n",
    "              [image_top_1_onehot], \n",
    "              epochs=1, \n",
    "              batch_size=nbatch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complete missing image_top_1s and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict({'text_tfidf_input': test_x_text, 'cat_input': test_x_cat, 'numerical_input': test_x_numerical})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glob/intel-python/versions/2018/intelpython3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning:\n",
      "\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "image_top_1_predictions = labelenc.inverse_transform(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_test_df = pd.DataFrame(test['item_id'])\n",
    "res_test_df['image_top_1_class'] = image_top_1_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_train_df = pd.DataFrame(train['item_id'])\n",
    "res_train_df['image_top_1_class'] = y_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check: compare between existing and learned image_top_1s (distribution wise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.856665e+06\n",
       "mean     1.255989e+03\n",
       "std      9.684190e+02\n",
       "min      0.000000e+00\n",
       "25%      4.320000e+02\n",
       "50%      1.092000e+03\n",
       "75%      2.218000e+03\n",
       "max      3.066000e+03\n",
       "Name: image_top_1_class, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_train_df['image_top_1_class'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    155197.000000\n",
       "mean       1872.631894\n",
       "std         598.249096\n",
       "min           0.000000\n",
       "25%        1320.000000\n",
       "50%        2195.000000\n",
       "75%        2262.000000\n",
       "max        3066.000000\n",
       "Name: image_top_1_class, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_test_df['image_top_1_class'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1008.0\n",
      "1     692.0\n",
      "2    3032.0\n",
      "3     796.0\n",
      "4    2264.0\n",
      "5     796.0\n",
      "6    2823.0\n",
      "7     567.0\n",
      "8     415.0\n",
      "9      46.0\n",
      "Name: image_top_1_class, dtype: float64\n",
      "3063\n"
     ]
    }
   ],
   "source": [
    "print(res_train_df['image_top_1_class'].head(10))\n",
    "print(res_train_df['image_top_1_class'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19    2262.0\n",
      "21     334.0\n",
      "32    2858.0\n",
      "38    2218.0\n",
      "55    2262.0\n",
      "60    1308.0\n",
      "68    2191.0\n",
      "69    2214.0\n",
      "74    2262.0\n",
      "91    2218.0\n",
      "Name: image_top_1_class, dtype: float64\n",
      "1712\n"
     ]
    }
   ],
   "source": [
    "print(res_test_df['image_top_1_class'].head(10))\n",
    "print(res_test_df['image_top_1_class'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking good..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.concat([res_train_df, res_test_df], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r_train_ids = r_train_ids.merge(res_df, on='item_id', how='left')\n",
    "r_test_ids = r_test_ids.merge(res_df, on='item_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_train_ids.to_csv(\"/home/u14303/Avito/completed_train_image_top_1_class.csv.gz\", compression='gzip', index=False)\n",
    "r_test_ids.to_csv(\"/home/u14303/Avito/completed_test_image_top_1_class.csv.gz\", compression='gzip', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Intel, 2018)",
   "language": "python",
   "name": "intel_distribution_of_python_3_2018"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
